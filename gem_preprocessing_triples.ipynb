{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gem preprocessing triples.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuroriM/GEM-table-to-text-through-AMR/blob/main/gem_preprocessing_triples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOx_W4GgO6Ie",
        "outputId": "5a8250f4-50ae-4aad-f8c9-04bdf8b93662"
      },
      "source": [
        "!pip install git+https://github.com/huggingface/datasets.git\n",
        "from datasets import load_dataset\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "import json\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/datasets.git\n",
            "  Cloning https://github.com/huggingface/datasets.git to /tmp/pip-req-build-0fpzujey\n",
            "  Running command git clone -q https://github.com/huggingface/datasets.git /tmp/pip-req-build-0fpzujey\n",
            "Requirement already satisfied (use --upgrade to upgrade): datasets==1.6.2.dev0 from git+https://github.com/huggingface/datasets.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2.dev0) (1.19.5)\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2.dev0) (3.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2.dev0) (0.3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2.dev0) (1.1.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2.dev0) (2.23.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2.dev0) (4.41.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2.dev0) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2.dev0) (0.70.11.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2.dev0) (2021.4.0)\n",
            "Requirement already satisfied: huggingface_hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2.dev0) (0.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2.dev0) (20.9)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2.dev0) (4.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.6.2.dev0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.6.2.dev0) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.6.2.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.6.2.dev0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.6.2.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.6.2.dev0) (2.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub<0.1.0->datasets==1.6.2.dev0) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==1.6.2.dev0) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib_metadata->datasets==1.6.2.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata->datasets==1.6.2.dev0) (3.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.6.2.dev0) (1.15.0)\n",
            "Building wheels for collected packages: datasets\n",
            "  Building wheel for datasets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for datasets: filename=datasets-1.6.2.dev0-cp37-none-any.whl size=224908 sha256=b485a484f0c8d1078aecddac01737c309f0f7d45e849fca4d9bb45a74cd386ad\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nol4yl0t/wheels/3e/af/ff/d1cdb5d0f9cff6eba2042a16b477ada497e23f1a3b6950b928\n",
            "Successfully built datasets\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKJQh6UQPB58"
      },
      "source": [
        "# find related verb form\n",
        "def normalize_relation_verb_webnlg(relation):\n",
        "\n",
        "    # modrelation = re.findall('[a-zA-Z][^A-Z]*', relation)[0]\n",
        "    modrelation = relation.replace('_', ' ')\n",
        "    # separate relations into multiple words where a capital letter mid-word is found\n",
        "    modrelation = re.findall(r'[a-zA-Z][^A-Z]*', modrelation)\n",
        "    \n",
        "    #modrelation = re.sub(r'[^\\w\\s]','', relation)\n",
        "    \n",
        "    relation = modrelation\n",
        "\n",
        "    # currently not normalizing words in multi-word relations: leads to a decrease in quality\n",
        "\n",
        "    # if isinstance(relation, list): \n",
        "    #     final_relation = []\n",
        "    #     for word in relation:\n",
        "            \n",
        "    #         lemmas = wn.lemmas(word)\n",
        "\n",
        "    #         if lemmas:\n",
        "    #             related_forms = [lemmas[i].derivationally_related_forms() for i in range(len(lemmas)) if lemmas[i].derivationally_related_forms()]\n",
        "\n",
        "    #             if related_forms:\n",
        "    #                 verb = related_forms[0][0].name()\n",
        "    #                 related_verb = verb.lower()\n",
        "\n",
        "               \n",
        "    #             verb_forms = wn.synsets(word, pos=\"v\")\n",
        "                \n",
        "    #             if verb_forms:\n",
        "    #                 verb = verb_forms[0].lemmas()[0].name()\n",
        "    #                 final_relation.append(verb.lower())\n",
        "    #             elif related_forms: \n",
        "    #                 final_relation.append(related_verb)\n",
        "    #         else:\n",
        "    #             final_relation.append(word.lower())\n",
        "    #     return 0, ' '.join(final_relation)\n",
        "\n",
        "\n",
        "\n",
        "    if len(relation) == 1:\n",
        "        relation = relation[0]\n",
        "        lemmas = wn.lemmas(relation)\n",
        "\n",
        "        if lemmas:\n",
        "            related_forms = [lemmas[i].derivationally_related_forms() for i in range(len(lemmas)) if lemmas[i].derivationally_related_forms()]\n",
        "\n",
        "            if related_forms:\n",
        "                verb = related_forms[0][0].name()\n",
        "                return 1, verb.lower()\n",
        "\n",
        "            \n",
        "            verb_forms = wn.synsets(relation, pos=\"v\")\n",
        "            if verb_forms:\n",
        "                verb = verb_forms[0].lemmas()[0].name()\n",
        "                return 1, verb.lower()\n",
        "\n",
        "        return 0, relation.lower()   \n",
        "     \n",
        "    return 0, ' '.join(relation).lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b3moakUPn70"
      },
      "source": [
        "def normalize_triple_entity(entity):\n",
        "    # modentity = re.sub(r'[^\\w\\s]','', entity)\n",
        "    modentity = entity.replace('_', ' ')\n",
        "    modentity = modentity.replace('\"', '')\n",
        "    \n",
        "    return modentity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twqH5tLmPi4E"
      },
      "source": [
        "def get_triples_text_pairs_webnlg(dframe, outfilename):\n",
        "    processed_webnlg = []\n",
        "\n",
        "    for i, row in dframe.iterrows():\n",
        "        current_triples = []\n",
        "        for j, triple in enumerate(row['tripleset']):\n",
        "            found, verb = normalize_relation_verb_webnlg(triple[1])\n",
        "            triple[0] = normalize_triple_entity(triple[0])\n",
        "            triple[1] = verb\n",
        "            triple[2] = normalize_triple_entity(triple[2])\n",
        "            \n",
        "            current_triples.append(\" \".join(triple))\n",
        "        processed_webnlg.append({\"triple-sents\": current_triples, \"text\": row['text']})\n",
        "\n",
        "    with open(outfilename, 'w') as f:\n",
        "      json.dump(processed_webnlg, f, ensure_ascii=False)\n",
        "\n",
        "    files.download(outfilename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92kBOOaSPwUd",
        "outputId": "9e7f6fca-5216-4ed7-f3c9-b58f5b32edb5"
      },
      "source": [
        "webnlg_data = load_dataset(\"gem\", \"web_nlg_en\")\n",
        "\n",
        "print(webnlg_data['train'][100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset gem (/root/.cache/huggingface/datasets/gem/web_nlg_en/1.1.0/a94b3f239aacc2081ffa3ea4414c3cddff25bb680c09756a27ec3e76547187b4)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'category': 'Airport', 'gem_id': 'web_nlg_en-train-100', 'gem_parent_id': 'web_nlg_en-train-100', 'input': ['Afonso_Pena_International_Airport | elevationAboveTheSeaLevel | 911.0'], 'references': [], 'target': 'Afonso Pena International airport is located 911 metres above sea level.', 'webnlg_id': 'train/Airport/1/Id42'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnWtS1FpQJDt"
      },
      "source": [
        "def get_triples_text_pairs_webnlg(data, outfilename):\n",
        "    processed_webnlg = []\n",
        "\n",
        "    for entry in data:\n",
        "        current_triples = []\n",
        "        \n",
        "        for triple in entry['input']:\n",
        "\n",
        "            triple = triple.split(\" | \")\n",
        "            \n",
        "            found, verb = normalize_relation_verb_webnlg(triple[1])\n",
        "            triple[0] = normalize_triple_entity(triple[0])\n",
        "            triple[1] = verb\n",
        "            triple[2] = normalize_triple_entity(triple[2])\n",
        "            \n",
        "            current_triples.append(\" \".join(triple))\n",
        "            \n",
        "        processed_webnlg.append({\"triple-sents\": current_triples, \"text\": entry['target'], \"gem_id\": entry['gem_id'], \"gem_parent_id\": entry['gem_parent_id']})\n",
        "        \n",
        "    with open(outfilename, 'w') as f:\n",
        "      json.dump(processed_webnlg, f, ensure_ascii=False)\n",
        "\n",
        "    files.download(outfilename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Z7De57s2R2sa",
        "outputId": "af23bec9-a186-4206-932d-10c736a81f20"
      },
      "source": [
        "get_triples_text_pairs_webnlg(webnlg_data['train'], 'gem_processed_webnlg_train.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1253e700-cf19-4e10-bd9f-e3175590efad\", \"gem_processed_webnlg_train.json\", 12954497)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "v4fG9fnxVubS",
        "outputId": "83ce6494-07cb-413d-bebb-afd207da50f2"
      },
      "source": [
        "get_triples_text_pairs_webnlg(webnlg_data['validation'], 'gem_processed_webnlg_dev.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a13bf82e-c58f-433c-83ae-203a666c9e87\", \"gem_processed_webnlg_dev.json\", 616281)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2HGeLsz5VvLA",
        "outputId": "257fbc1f-dbb7-4f2d-e22e-a0d7c51d1f59"
      },
      "source": [
        "get_triples_text_pairs_webnlg(webnlg_data['test'], 'gem_processed_webnlg_test.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_216b4b60-fd80-48a2-8bcd-8d9359424119\", \"gem_processed_webnlg_test.json\", 703045)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}