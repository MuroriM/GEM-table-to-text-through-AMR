{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMR valid - postprocessor",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuroriM/GEM-table-to-text-through-AMR/blob/main/AMR_valid_postprocessor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0qDWQcKiDQa"
      },
      "source": [
        "# AMR linearizerÂ  \n",
        "This converts AMRs from Penman notation to their linear equivalent. This includes stripping of variables, newline characters, and other whitespaces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vdd7-LlAek4",
        "outputId": "10ec5a66-1cb1-45f4-93f6-4d2128dcd739"
      },
      "source": [
        "!pip install amrlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: amrlib in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from amrlib) (1.19.5)\n",
            "Requirement already satisfied: penman>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from amrlib) (1.2.0)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from amrlib) (1.8.1+cu101)\n",
            "Requirement already satisfied: smatch in /usr/local/lib/python3.7/dist-packages (from amrlib) (1.0.4)\n",
            "Requirement already satisfied: transformers>=3.0 in /usr/local/lib/python3.7/dist-packages (from amrlib) (4.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from amrlib) (4.41.1)\n",
            "Requirement already satisfied: spacy>=2.0 in /usr/local/lib/python3.7/dist-packages (from amrlib) (2.2.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->amrlib) (3.7.4.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0->amrlib) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0->amrlib) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0->amrlib) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0->amrlib) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0->amrlib) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0->amrlib) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0->amrlib) (2019.12.20)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->amrlib) (56.1.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->amrlib) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->amrlib) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->amrlib) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->amrlib) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->amrlib) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->amrlib) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->amrlib) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->amrlib) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->amrlib) (2.0.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=3.0->amrlib) (3.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0->amrlib) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0->amrlib) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0->amrlib) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0->amrlib) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0->amrlib) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0->amrlib) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0->amrlib) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=3.0->amrlib) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHUTT46j-W2K",
        "outputId": "df73fa1b-04fb-415c-fe60-02ee629f0426"
      },
      "source": [
        "# remove files from previous sessions\n",
        "\n",
        "!ls\n",
        "!rm -r AMR test_web smatch\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AMR  sample_data  test_web\n",
            "rm: cannot remove 'smatch': No such file or directory\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INbgQvGB5-7n",
        "outputId": "14a99e17-7e5e-4a32-afa0-418ea2543b9f"
      },
      "source": [
        "# load dev, train, test, webnlg data\n",
        "\n",
        "# /content/test_web/webnlg_dev_parsed.jsonl.tf\n",
        "# /content/test_web/webnlg_test_parsed.jsonl.tf\n",
        "# /content/test_web/webnlg_test_parsed.jsonl.tf\n",
        "# respective paths\n",
        "\n",
        "!git clone https://github.com/MuroriM/test_web.git\n",
        "# https://github.com/MuroriM/test_web"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'test_web'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 16 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpQDrQmCsWKn"
      },
      "source": [
        "# Character-based AMR translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afJNNFfUZzo8",
        "outputId": "10591cdd-04f7-453e-fb2a-a79436b37c7f"
      },
      "source": [
        "!git clone https://github.com/RikVN/AMR.git\n",
        "# https://github.com/RikVN/AMR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AMR'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Total 127 (delta 0), reused 0 (delta 0), pack-reused 127\u001b[K\n",
            "Receiving objects: 100% (127/127), 209.88 KiB | 2.12 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gJFeJAGZ4TS",
        "outputId": "02b91430-224b-469b-8867-f97c4c6ff3a5"
      },
      "source": [
        "%cd /content/AMR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/AMR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6oif5W0Z61z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c016c6eb-565f-4907-e089-094b57612cf0"
      },
      "source": [
        "!git clone https://github.com/snowblink14/smatch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'smatch'...\n",
            "remote: Enumerating objects: 147, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 147 (delta 0), reused 2 (delta 0), pack-reused 144\u001b[K\n",
            "Receiving objects: 100% (147/147), 74.56 KiB | 1.52 MiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kev-EUI1Z9Qb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3686652-e4ec-4311-ce90-89d149ad811d"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (4.2.6)\n",
            "Requirement already satisfied: BeautifulSoup4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 3)) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Swq1dc0AHYj"
      },
      "source": [
        "# This step is important! \n",
        "# Though a temporary fix\n",
        "!cp amr_utils.py restoreAMR\n",
        "!cp best_amr_permutation.py restoreAMR\n",
        "!cp var_free_amrs.py restoreAMR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLdZC5JLOkh7"
      },
      "source": [
        "## Create test dataset\n",
        "!head -3 /content/test_web/webnlg_test_target.json > /content/test_web/test_repo.jsonl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "bl8IqXN06uqX"
      },
      "source": [
        "#@title\n",
        "# # Converts linearized AMRs to Penman notation\n",
        "# # Convert original WebNLP Source pairs\n",
        "# # Not needed for our current use\n",
        "\n",
        "# import json\n",
        "\n",
        "# # Loads linear AMRs from dataset and stores the Penman AMRs in new dataset\n",
        "# def linear_to_penman_dataset(input_file):\n",
        "  \n",
        "#     modified_entries = []\n",
        "#     for line in open(input_file, 'r'):\n",
        "#       modified_entry = {}\n",
        "\n",
        "#       line_json = json.loads(line)\n",
        "#       source = line_json[\"source_amrs\"]\n",
        "#       output = line_json[\"output_amr\"]\n",
        "\n",
        "#       # convert source and output amrs to Penman notation\n",
        "#       new_source = linear_to_penman(source)\n",
        "#       new_output = linear_to_penman(source)\n",
        "\n",
        "#       modified_entry[\"source_amrs\"] = new_source\n",
        "#       modified_entry[\"output_amr\"] = new_output\n",
        "      \n",
        "#       modified_entries.append(json.dumps(modified_entry))\n",
        "\n",
        "\n",
        "#     with open(input_file + \".penman\", 'w') as f:\n",
        "#         for entry in modified_entries:\n",
        "#             f.write(\"%s\\n\" % entry)\n",
        "\n",
        "\n",
        "# # Convert linear AMR to Penman\n",
        "# ######################\n",
        "# # This is the function to use\n",
        "# ######################\n",
        "# def linear_to_penman(amr):\n",
        "#     with open('/content/temp_converter/entry.jsonl', 'w') as f:\n",
        "#       f.write(amr)\n",
        "\n",
        "#     linear_to_penman_pipeline()\n",
        "\n",
        "#     with open('/content/temp_converter/entry.jsonl.restored.txt', 'r') as f:\n",
        "#       penman_amr = f.read().rstrip()\n",
        "\n",
        "#     return penman_amr\n",
        "\n",
        "\n",
        "# # Pipeline that calls the files to convert linear to AMR\n",
        "# def linear_to_penman_pipeline():\n",
        "#     !python char_level_AMR.py -f  /content/temp_converter/entry.jsonl  --super_chars\n",
        "#     !python restoreAMR/restore_amr.py -f /content/temp_converter/entry.jsonl -o /content/temp_converter/entry.jsonl.restored\n",
        "#     !python reformat_single_amrs.py -f /content/temp_converter/entry.jsonl.restored -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUcf98lsKIPN",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# # Converts linearized AMRs to Penman notation\n",
        "# # Outdated function - converts a single AMR instead of a file full of AMRs\n",
        "# import json\n",
        "\n",
        "# # Loads linear AMRs from dataset and stores the Penman AMRs in new dataset\n",
        "# def linear_to_penman_dataset(input_file):\n",
        "  \n",
        "#     modified_entries = []\n",
        "#     for line in open(input_file, 'r'):\n",
        "#       modified_entry = {}\n",
        "\n",
        "#       amr = json.loads(line)\n",
        "\n",
        "#       # convert source and output amrs to Penman notation\n",
        "#       new_amr = linear_to_penman(amr)\n",
        "      \n",
        "#       modified_entries.append(new_amr)\n",
        "\n",
        "#     output_file = input_file.replace(\".json\", \"_penman.json\")\n",
        "#     with open(output_file, 'w') as f:\n",
        "#         for entry in modified_entries:\n",
        "#             f.write(json.dumps(entry) + \"\\n\")\n",
        "\n",
        "\n",
        "# # Convert linear AMR to Penman\n",
        "# ######################\n",
        "# # This is the function to use\n",
        "# ######################\n",
        "# def linear_to_penman(amr):\n",
        "#     with open('/content/temp_converter/entry.jsonl', 'w') as f:\n",
        "#       f.write(amr)\n",
        "\n",
        "#     linear_to_penman_pipeline()\n",
        "\n",
        "#     with open('/content/temp_converter/entry.jsonl.restored.txt', 'r') as f:\n",
        "#       penman_amr = f.read().rstrip()\n",
        "\n",
        "#     return penman_amr\n",
        "\n",
        "\n",
        "# # Pipeline that calls the files to convert linear to AMR\n",
        "# def linear_to_penman_pipeline():\n",
        "#     !python char_level_AMR.py -f  /content/temp_converter/entry.jsonl  --super_chars \n",
        "#     !python restoreAMR/restore_amr.py -f /content/temp_converter/entry.jsonl -o /content/temp_converter/entry.jsonl.restored\n",
        "#     !python reformat_single_amrs.py -f /content/temp_converter/entry.jsonl.restored -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTIq744Hg48J",
        "outputId": "1254721b-c228-40ac-df71-8de1461936b8"
      },
      "source": [
        "from amr_utils import countparens\n",
        "\n",
        "\n",
        "def countbrackets(amr):\n",
        "  return amr.count(\"(\") - amr.count(\")\")\n",
        "\n",
        "infile = '/content/test_web/webnlg_gen.txt'\n",
        "\n",
        "with open(infile, 'r') as f:\n",
        "    lines = f.read()[:-1]\n",
        "    amrs = lines.split(\"\\n\")  \n",
        "            \n",
        "    total_valid = 0\n",
        "    total_amrs = 0\n",
        "\n",
        "    with open(infile.replace(\".txt\", \"_bracketized.txt\"), 'w') as f_out:\n",
        "\n",
        "        for i, amr in enumerate(amrs):\n",
        "            brackets = countbrackets(amr)\n",
        "\n",
        "            while brackets != 0:\n",
        "              if brackets < 0:\n",
        "                amr = amr[:-1]\n",
        "              else:\n",
        "                amr = amr + ')'\n",
        "              brackets = countbrackets(amr)\n",
        "\n",
        "            if countparens(amr):\n",
        "              total_valid += 1\n",
        "            else:\n",
        "              print(amr)\n",
        "\n",
        "            total_amrs += 1\n",
        "\n",
        "            f_out.write(amr)\n",
        "            if i != len(amrs)-1:\n",
        "              f_out.write(\"\\n\")\n",
        "\n",
        "        # print(valid_amr(amr))\n",
        "\n",
        "    #         total_valid = 0\n",
        "    #         total_amrs = 0\n",
        "    #         for amr in amrs:\n",
        "    #             is_valid = valid_amr(amr) \n",
        "    #             if(is_valid == True):\n",
        "    #                 total_valid += 1\n",
        "    #             total_amrs += 1\n",
        "    print(\"Valid AMRs / Total # Output:\")\n",
        "    print(total_valid, \"/\", total_amrs)  \n",
        "        # print(countparens(amr), brackets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valid AMRs / Total # Output:\n",
            "1779 / 1779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuPNk5Om76LE"
      },
      "source": [
        "# Convert amrs conpied into the temp files below into their Penman notation\n",
        "def to_penman():\n",
        "  !python char_level_AMR.py -f  /content/test_web/test.jsonl  --super_chars --amr_ext \".jsonl\"\n",
        "  !python restoreAMR/restore_amr.py -f /content/test_web/test.char.jsonl -o /content/test_web/test.char.restored.json\n",
        "  !python reformat_single_amrs.py -f /content/test_web/test.char.restored.json -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J8nLi0dwNEU"
      },
      "source": [
        "from google.colab import files\n",
        "import re\n",
        "# Convert amrs in the input file into the Penman notation\n",
        "def convert_file_to_penman(inputfile):\n",
        "  \n",
        "  # Preprocess the AMRs\n",
        "  with open(inputfile, 'r') as f:\n",
        "    lines = f.read()#[:-1]\n",
        "    amrs = lines.split(\"\\n\")\n",
        "    amrs = [amr[1:-3] for amr in amrs]       # Remove the start and end quotes\n",
        "    amrs = [re.sub('\\\\\\\\', '', amr) for amr in amrs]  # remove excess escape characters\n",
        "  # Copy the processed input file AMRs into a temporary file\n",
        "  with open('/content/test_web/test.jsonl', 'w') as f:\n",
        "    f.write(amrs[0])\n",
        "    for amr in amrs[1:]:\n",
        "      f.write(\"\\n\" + amr)\n",
        "\n",
        "\n",
        "  # Convert linearized AMRS in the temporary file to their Penman notation\n",
        "  to_penman()\n",
        "\n",
        "\n",
        "  # Copy converted AMRs from temporary files to intended output file\n",
        "  with open('/content/test_web/test.char.restored.json.txt', 'r') as f:\n",
        "    lines = f.read()\n",
        "\n",
        "  outputfile = inputfile.replace(\".json\", \"_penman.json\")\n",
        "  with open(outputfile, 'w') as f:\n",
        "    f.write(lines)\n",
        "\n",
        "  # Uncomment to download the output file\n",
        "  # files.download(outputfile) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v8WYhYn730f"
      },
      "source": [
        "# Convert linear AMRs to Penman noation\n",
        "\n",
        "# convert_file_to_penman('/content/test_web/test_repo.jsonl')   # test file\n",
        "# convert_file_to_penman('/content/test_web/webnlg_test_target.json')   # webnlg_test\n",
        "# convert_file_to_penman('/content/webnlg_test_source.json')   # webnlg_test\n",
        "# convert_file_to_penman('/content/webnlg_test_target.json')   # webnlg_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzFFEkMld_zU"
      },
      "source": [
        "# !ls ./test_web\n",
        "# convert_file_to_penman('test_web/webnlg_test_source.json')   # webnlg_test\n",
        "# convert_file_to_penman('test_web/webnlg_test_target.json')   # webnlg_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq3xhzLZscga"
      },
      "source": [
        "# # Uncomment to download the dev, test and train sets\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download('/content/test_web/webnlg_test_target_penman.json') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "6VbykrgJWqKV"
      },
      "source": [
        "#@title\n",
        "# failed approach at brute amr concatenation\n",
        "\n",
        "# for line in open(\"/content/test_web/test2.jsonl\", 'r'):\n",
        "#   line_json = json.loads(line)\n",
        "#   source = line_json[\"source_amrs\"]\n",
        "#   amr_attr = []\n",
        "#   headFound = False\n",
        "#   for s in source:\n",
        "#     # print(s, valid_amr(s))\n",
        "#     s_split = s.split(\"\\n\")\n",
        "#     if not headFound:\n",
        "#       head = s_split[0]\n",
        "#       headFound = True\n",
        "#     attr = \"\\n\".join(s_split[1:])\n",
        "#     amr_attr.append(attr)\n",
        "#     # print(attr)\n",
        "#   # new_amr = head + \"\\n\" + \"\\n\".join(amr_attr)\n",
        "#   new_amr = head + \"\\n\" + amr_attr[0]  + \"\\n\" +  amr_attr[0].replace(\"location\", \"ARG1\").replace(\":name\", \":ARG2\")\n",
        "#   print(new_amr, valid_amr(new_amr))\n",
        "#   print()\n",
        "#   print(\"\\n\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyEJPxzNbuOv"
      },
      "source": [
        "# from amr_utils import valid_amr\n",
        "\n",
        "# # count how many AMRs in Penman notation file are in valid format\n",
        "# def check_penman_validity(inputfile):\n",
        "\n",
        "#     with open(inputfile, 'r') as f:\n",
        "#         lines = f.read()[:-1]\n",
        "#         amrs = lines.split(\"\\n\\n\")\n",
        "#         total_valid = 0\n",
        "#         total_amrs = 0\n",
        "#         for amr in amrs:\n",
        "#             is_valid = valid_amr(amr) \n",
        "#             if(is_valid == True):\n",
        "#                 total_valid += 1\n",
        "#             total_amrs += 1\n",
        "#     print(\"Valid AMRs / Total # Output:\")\n",
        "#     print(total_valid, \"/\", total_amrs)  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTahK2EEdIC_"
      },
      "source": [
        "# convert_file_to_penman('/content/webnlg_gen')\n",
        "# check_penman_validity('test_web/webnlg_test_target_penman.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOq3BCtOoyDB"
      },
      "source": [
        "# from amr_utils import countparens\n",
        "# import json\n",
        "\n",
        "# def countparens_file(inputfile):\n",
        "#     with open(inputfile) as file:\n",
        "#         lines = file.read()\n",
        "#         amrs = lines.split(\"\\n\")[:-1]\n",
        "#         print(len(amrs))\n",
        "        \n",
        "#         valid_outputs = 0\n",
        "#         total_outputs = 0\n",
        "#         for amr in amrs:\n",
        "          \n",
        "#             amr = json.loads(amr)\n",
        "#             amr = amr['output_amr']\n",
        "#             if valid_amr(amr):\n",
        "#                 # print(amr)   \n",
        "#                 valid_outputs += 1\n",
        "            \n",
        "#             # if(countparens(amr)):\n",
        "#             #     # print(\"Balanced parens example\", valid_outputs)\n",
        "#             #     # print(amr)\n",
        "#             #     # print(\"\\n\")\n",
        "#             #     valid_outputs += 1\n",
        "#             else:\n",
        "#                 print(amr)\n",
        "#             #     pass\n",
        "#             total_outputs += 1\n",
        "\n",
        "#     print(f\"{100*(valid_outputs / total_outputs):.2f}%, {total_outputs-valid_outputs}\")\n",
        "#     return\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqzZ5vaWo78x"
      },
      "source": [
        "from amr_utils import countparens\n",
        "def countparens_file(inputfile):\n",
        "    with open(inputfile) as file:\n",
        "        lines = file.read()\n",
        "        amrs = lines.split(\"\\n\")\n",
        "        \n",
        "        valid_outputs = 0\n",
        "        total_outputs = 0\n",
        "        for amr in amrs:\n",
        "            if(countparens(amr)):\n",
        "                # print(\"Balanced parens example\", valid_outputs)\n",
        "                # print(amr)\n",
        "                # print(\"\\n\")\n",
        "                valid_outputs += 1\n",
        "            else:\n",
        "                print(amr)\n",
        "            total_outputs += 1\n",
        "\n",
        "    print(f\"{100*(valid_outputs / total_outputs):.2f}%\")\n",
        "    return\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUsFnwfBjEDT"
      },
      "source": [
        "# countparens_file('/content/test_web/webnlg_gen.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MnUyJHga0sd"
      },
      "source": [
        "# from amr_utils import countparens\n",
        "# valid_amr(\"(h0 / have-org-role-91\\n      :ARG2 (c2 / capital)\\n      :ARG0 (c1 / country\\n            :name (n1 / name\\n                  :op1 \\\"U.K.\\\" ))\\n      :ARG1 (c0 / city\\n            :name (n0 / name\\n                  :op1 \\\"London\\\" )))\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDKXNicXsNq-"
      },
      "source": [
        "# countparens_file('/content/test_web/webnlg_train_parsed.jsonl')\n",
        "# not sure why the script claims there are 4 unbalanced-paren amrs in the train set: I checked these by hand and they seem to be balanced"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGBXNKkwjRax",
        "outputId": "4da35afb-5c25-4bc1-ebcb-f40add528a0e"
      },
      "source": [
        "countparens_file('/content/test_web/webnlg_dev_parsed.jsonl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "_n3fXWTpm-WU",
        "outputId": "ed4f33d9-fcbe-4f35-a787-6eb6a09e4328"
      },
      "source": [
        "countparens_file('/content/test_web/webnlg_gen.txt.out')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-6f94d1cba126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcountparens_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/test_web/webnlg_gen.txt.out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-db2c04ee9e22>\u001b[0m in \u001b[0;36mcountparens_file\u001b[0;34m(inputfile)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mamr_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcountparens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcountparens_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mamrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/test_web/webnlg_gen.txt.out'"
          ]
        }
      ]
    }
  ]
}